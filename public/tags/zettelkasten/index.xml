<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Zettelkasten on Mischa van den Burg</title>
    <link>https://mischavandenburg.com/tags/zettelkasten/</link>
    <description>Recent content in Zettelkasten on Mischa van den Burg</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 04 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://mischavandenburg.com/tags/zettelkasten/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Get a free 4 CPU 24GB Ram VM on from Oracle</title>
      <link>https://mischavandenburg.com/zet/free-oracle-vm/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/free-oracle-vm/</guid>
      <description>A few weeks ago someone gave me a tip. Oracle actually has a really good free tier offering.
You can host a 4CPU 24GB VM for free!
This is perfect for a lab environment.
I spent my evening creating the VM and setting up a kubernetes cluster from scratch.
Use this video to claim your free vm:
https://www.youtube.com/watch?v=NKc3k7xceT8</description>
      <content:encoded><![CDATA[<p>A few weeks ago someone gave me a tip. Oracle actually has a really good free tier offering.</p>
<p>You can host a 4CPU 24GB VM for free!</p>
<p>This is perfect for a lab environment.</p>
<p>I spent my evening creating the VM and setting up a kubernetes cluster from scratch.</p>
<p>Use this video to claim your free vm:</p>
<p><a href="https://www.youtube.com/watch?v=NKc3k7xceT8">https://www.youtube.com/watch?v=NKc3k7xceT8</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Setting up automated backups on my Arch Linux system with rsync and bash</title>
      <link>https://mischavandenburg.com/zet/arch-backup-setup-1/</link>
      <pubDate>Sat, 21 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/arch-backup-setup-1/</guid>
      <description>For the past few months I&amp;rsquo;ve been stuyding every hour of free time that I had. Now that I reached my certification goals for now, I finally had some time to do a chore I had been meaning to do for a long time.
My Arch Linux system is fully encrypted, and I make backups. But I was still doing it a bit haphazardly, usually every Friday.
I wanted to automate this for a long time now, but I never got round to it.</description>
      <content:encoded><![CDATA[<p>For the past few months I&rsquo;ve been stuyding every hour of free time that I had. Now that I reached my certification goals for now, I finally had some time to do a chore I had been meaning to do for a long time.</p>
<p>My Arch Linux system is fully encrypted, and I make backups. But I was still doing it a bit haphazardly, usually every Friday.</p>
<p>I wanted to automate this for a long time now, but I never got round to it. Today I made the first steps, but it is still in progress.</p>
<p>Naturally, I could use a tool like Timeshift or something similar to schedule my backups. However, I want to do it myself using rsync because I want to fully understand what I am backing up, when, and where. Rsync is also used in our environment at work, so I assume it is more common in enterprise and production environments.</p>
<h2 id="full-system-backup">full system backup</h2>
<p>Before I was making a full system backup every Friday using this command:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">sudo rsync -aAXH --info<span class="o">=</span>stats1,progress2 --exclude<span class="o">={</span><span class="s2">&#34;/dev/*&#34;</span>,<span class="s2">&#34;/proc/*&#34;</span>,<span class="s2">&#34;/sys/*&#34;</span>,<span class="s2">&#34;/tmp/*&#34;</span>,<span class="s2">&#34;/run/*&#34;</span>,<span class="s2">&#34;/mnt/*&#34;</span>,<span class="s2">&#34;/media/*&#34;</span>,<span class="s2">&#34;/lost+found&#34;</span>,<span class="s2">&#34;/home/*/.cache/*&#34;</span>,<span class="s2">&#34;/data-hdd/&#34;</span>,<span class="s2">&#34;/games/&#34;</span>,<span class="s2">&#34;/var/lib/docker/*&#34;</span>,<span class="s2">&#34;/home/mischa/music/*&#34;</span>,<span class="s2">&#34;/swapfile&#34;</span>, <span class="s2">&#34;/data-hdd2/&#34;</span>, <span class="s2">&#34;/data-hdd3/&#34;</span><span class="o">}</span> / /data-hdd/backups/arch-beast/01-01-23
</span></span></code></pre></div><p>This command creates a full backup of my entire root filesystem, and it should be possible to restore my entire system by just reversing the target and destination in the end.</p>
<p>However, as I was coming up with my new strategy, I thought this was overkill.</p>
<h2 id="slimming-down">slimming down</h2>
<p>All I really need to back up is my home directory and it would be nice to have my /etc directory backed up as well.</p>
<p>So I wrote a simple shell script to do this:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="cp">#!/bin/bash
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="nv">BACKUPS_DESTINATION</span><span class="o">=</span><span class="s2">&#34;/data-hdd/backups/arch-beast&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># format:</span>
</span></span><span class="line"><span class="cl"><span class="c1"># rsync -a --delete --quiet /path/to/backup /location/of/backup</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># stop the script if an error occurs</span>
</span></span><span class="line"><span class="cl"><span class="nb">set</span> -e
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">rsync -a --delete --quiet --exclude<span class="o">=</span><span class="s2">&#34;{&#34;</span>/home/*/.cache/*<span class="s2">&#34;}&#34;</span> /home/mischa <span class="nv">$BACKUPS_DESTINATION</span>/home
</span></span><span class="line"><span class="cl">rsync -a --delete --quiet /etc <span class="nv">$BACKUPS_DESTINATION</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;Made backups on: </span><span class="k">$(</span>date<span class="k">)</span><span class="s2">&#34;</span> &gt;&gt; /var/log/backup.log
</span></span></code></pre></div><p>-a flag from man page:</p>
<p><em>&ldquo;This  is  equivalent to -rlptgoD.  It is a quick way of saying you want recursion and want to preserve almost everything.&rdquo;</em></p>
<p>&ndash;delete: means files deleted on the source are to be deleted on the backup as well</p>
<h2 id="automation">automation</h2>
<p>I have a few scripts running in cronjobs on my system. I have a goal of putting them all in systemd timers, but I haven&rsquo;t gotten round to it yet. For now, I will just add my backup scripts to my existing cronjobs setup.</p>
<p>To make my backups every day, I added this to my crontab:</p>
<p><code>0 12 * * * /bin/bash /home/mischa/git/lab/bash/backup</code></p>
<p>Every day it will make a backup to the same directory and update the changed files, or delete the files I deleted from my system.</p>
<p>I also wanted to have a weekly backup happening on Monday.</p>
<p>I will make a more elaborate script to make a weekly directory, and rotate it with a new directory every week. But for now, I just chose a quick solution by creating a weekly version of my script and running it every Monday.</p>
<p>The only difference is the path:</p>
<p><code>BACKUPS_DESTINATION=&quot;/data-hdd/backups/arch-beast/weekly&quot;</code></p>
<p>In the crontab:</p>
<p><code>0 10 * * 1 /bin/bash /home/mischa/git/lab/bash/backup-weekly</code></p>
<h2 id="to-do">to do</h2>
<ul>
<li>set up weekly backup in the same script</li>
<li>create error handling and improve logging</li>
<li>set up in systemd timers instead of crontab</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>I passed the AZ-400 DevOps Expert today</title>
      <link>https://mischavandenburg.com/zet/passed-az-400/</link>
      <pubDate>Sat, 14 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/passed-az-400/</guid>
      <description>I&amp;rsquo;m typing this 30 minutes after I passed my AZ-400 exam. I&amp;rsquo;m sitting in a lovely cafe on Leidseplein in Amsterdam and feel relieved. Another significant certification bites the dust. This one took about 70 hours of study.
I started preparing immediately after passing my AZ-104 exam, which was a good move. The AZ-400 requires you to know many details about Azure services and how to access them. For example, Shared Access Signatures are only used for accessing storage accounts, but they came up quite often as alternative answers to the questions.</description>
      <content:encoded><![CDATA[<p>I&rsquo;m typing this 30 minutes after I passed my AZ-400 exam. I&rsquo;m sitting in a lovely cafe on Leidseplein in Amsterdam and feel relieved. Another significant certification bites the dust. This one took about 70 hours of study.</p>
<p>I started preparing immediately after passing my AZ-104 exam, which was a good move. The AZ-400 requires you to know many details about Azure services and how to access them. For example, Shared Access Signatures are only used for accessing storage accounts, but they came up quite often as alternative answers to the questions.</p>
<p>The exam itself was difficult, but the AZ-104 was harder. The AZ-104 exam was more challenging because the questions were complicated and required you to simultaneously balance many different factors in the mind. The AZ-400 was difficult because the answer alternatives that are provided are incredibly similar to each other, and they make you very insecure about what the right choice might be. As a result, I changed my answers many times.</p>
<p>I will do another study guide for this certification soon and publish my notes and Anki deck too. Now it&rsquo;s time to celebrate and relax a little.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Azure DevOps Personal Access Tokens are always for authenticating into ADO</title>
      <link>https://mischavandenburg.com/zet/azure-personal-access-tokens/</link>
      <pubDate>Fri, 13 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/azure-personal-access-tokens/</guid>
      <description>The PAT (Personal Access Token) often comes up during practice tests for the AZ-400.
One way to remember when to use a PAT is that these are only for authenticating into Azure DevOps, never to external services.
For example, you might get a question on connecting your Azure DevOps project with a GitHub account from Azure DevOps, and PAT will show up as one of the alternative answers. By remembering that PATs are only for authenticating into ADO, you can elminate this alternative, and make your choice easier.</description>
      <content:encoded><![CDATA[<p>The PAT (Personal Access Token) often comes up during practice tests for the AZ-400.</p>
<p>One way to remember when to use a PAT is that these are only for authenticating <strong>into</strong> Azure DevOps, never to external services.</p>
<p>For example, you might get a question on connecting your Azure DevOps project with a GitHub account from Azure DevOps, and PAT will show up as one of the alternative answers. By remembering that PATs are only for authenticating into ADO, you can elminate this alternative, and make your choice easier.</p>
<p>Personal Access Tokens are an alternative to passwords but should be treated in exactly the same way.</p>
<p><a href="https://learn.microsoft.com/en-us/azure/devops/organizations/accounts/use-personal-access-tokens-to-authenticate?view=azure-devops&amp;tabs=Windows">https://learn.microsoft.com/en-us/azure/devops/organizations/accounts/use-personal-access-tokens-to-authenticate?view=azure-devops&amp;tabs=Windows</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>The Pomodoro technique has won me over</title>
      <link>https://mischavandenburg.com/zet/pomodoro/</link>
      <pubDate>Fri, 13 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/pomodoro/</guid>
      <description>I did a lot of studying last year, and I achieved a few tough certifications. I&amp;rsquo;ve always been good at studying and never struggled with getting decent grades in university. As a result, I never felt the need to use particular techniques to pass my tests. However, now that I need to do my studies combined with a full-time job, I did some optimization and looked into study techniques.
One technique I&amp;rsquo;ve become very fond of is the Pomodoro Technique.</description>
      <content:encoded><![CDATA[<p>I did a lot of studying last year, and I achieved a few tough certifications. I&rsquo;ve always been good at studying and never struggled with getting decent grades in university. As a result, I never felt the need to use particular techniques to pass my tests. However, now that I need to do my studies combined with a full-time job, I did some optimization and looked into study techniques.</p>
<p>One technique I&rsquo;ve become very fond of is the Pomodoro Technique. I don&rsquo;t have any problems focusing for long periods, but I still decided to try it. I use the standard 25-minute study with a 5-minute break routine, and after four cycles, I take a 30-minute break.</p>
<p>The Pomodoro technique has been a way to force myself to take breaks, which I wasn&rsquo;t used to. I used to chip away at a specific task for hours. However, I discovered that when I take a break, walk around for five minutes, and apply myself to the task again, my mind is in a fresh state and much more receptive to the information. Perhaps the time I spend studying after a break is actually more productive because the mind had a little rest.</p>
<p>The technique also pushed my limits a bit more. I study more hours a day, considering that I also work full time. There is this moment where I want to quit studying, but I ask myself, &ldquo;do I have another Pomodoro in me?&rdquo;</p>
<p>Now that I&rsquo;ve gotten used to breaking things up into 25-minute chunks of time, I started using the Pomodoro technique for other areas in life as well, such as blog writing or coding projects.</p>
<p>You can use any tool you like to start using the Pomodoro technique and pick any break schedule that suits you. I&rsquo;ll link some resources below. All you need is some sort of timer. You can use a timer on your computer or a physical timer. I use the Forest app on my iPhone because it integrates with the iOs &ldquo;do not disturb&rdquo; and &ldquo;focus&rdquo; modes, so  I don&rsquo;t get any distracting notifications when I&rsquo;m on a Pomodoro.</p>
<p><a href="https://science.nichd.nih.gov/confluence/display/newsletter/2020/05/07/The+Pomodoro+Technique%3A+An+Effective+Time+Management+Tool">https://science.nichd.nih.gov/confluence/display/newsletter/2020/05/07/The+Pomodoro+Technique%3A+An+Effective+Time+Management+Tool</a></p>
<p><a href="https://www.youtube.com/watch?v=5WRO79zuJ4U">https://www.youtube.com/watch?v=5WRO79zuJ4U</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Using parameter expansion as search and replace</title>
      <link>https://mischavandenburg.com/zet/slash-syntax-replace/</link>
      <pubDate>Tue, 10 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/slash-syntax-replace/</guid>
      <description>Last modified: 2023-01-10
In this evening&amp;rsquo;s studies I came across this bash script in a tutorial by Rob Muhlenstein:
!#/bin/bash echo -e ${PATH//:/\\n} I could not make heads or tails of all these slashes and curly braces, since the output clearly indicated that search and replacement was being performed. I&amp;rsquo;m used to the sed / vim syntax: s/foo/bar
After some research I learned that &amp;lsquo;//&amp;rsquo; is a global search and replace syntax of several text processing programs.</description>
      <content:encoded><![CDATA[<p><em>Last modified: 2023-01-10</em></p>
<p>In this evening&rsquo;s studies I came across this bash script in a tutorial by Rob Muhlenstein:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">!#/bin/bash
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> -e <span class="si">${</span><span class="nv">PATH</span><span class="p">//:/</span><span class="se">\\</span><span class="nv">n</span><span class="si">}</span>
</span></span></code></pre></div><p>I could not make heads or tails of all these slashes and curly braces, since the output clearly indicated that search and replacement was being performed. I&rsquo;m used to the sed / vim syntax: <code>s/foo/bar</code></p>
<p>After some research I learned that &lsquo;//&rsquo; is a global search and replace syntax of several text processing programs. It is known as parameter expansion in bash.</p>
<p>Example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nv">foo</span><span class="o">=</span><span class="s2">&#34;1234567890&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;</span><span class="si">${</span><span class="nv">foo</span><span class="p">//[0-9]/x</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span></code></pre></div><p>This replaces all the digits in the $foo variable with &lsquo;x&rsquo;, so the output would be xxxxxxxxxx</p>
<p>To do this with sed, you would do:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;</span><span class="nv">$foo</span><span class="s2">&#34;</span> <span class="p">|</span> sed <span class="s1">&#39;s/[0-9]/x/g&#39;</span>
</span></span></code></pre></div><p>For more info:</p>
<p><code>man bash</code></p>
<p><code>/parameter expansion</code></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Automatically adding my recent blog posts to my GitHub Readme</title>
      <link>https://mischavandenburg.com/zet/adding-posts-github-readme/</link>
      <pubDate>Mon, 09 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/adding-posts-github-readme/</guid>
      <description>My friend gave me a nice tip for customizing the readme on my personal GitHub page. I discovered there is a whole world of plugins and customizations out there.
I set up this one for my GitHub homepage. It uses a workflow to update the readme in my personal GitHub repo with the most recent posts from this blog, based on the RSS feed. Neat!
It was very easy to set up.</description>
      <content:encoded><![CDATA[<p>My friend gave me a nice tip for customizing the readme on my personal GitHub page. I discovered there is a whole world of plugins and customizations out there.</p>
<p>I set up <a href="https://github.com/abhisheknaiidu/awesome-github-profile-readme">this one</a> for my GitHub homepage. It uses a workflow to update the readme in my personal GitHub repo with the most recent posts from this blog, based on the RSS feed. Neat!</p>
<p>It was very easy to set up. If you don&rsquo;t have your own blog, you could configure it with a different RSS feed. Hacker News for example.</p>
<p><a href="https://github.com/gautamkrishnar/blog-post-workflow">https://github.com/gautamkrishnar/blog-post-workflow</a></p>
<p><a href="https://github.com/abhisheknaiidu/awesome-github-profile-readme">https://github.com/abhisheknaiidu/awesome-github-profile-readme</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Fall in love with sed.</title>
      <link>https://mischavandenburg.com/zet/fall-in-love-with-sed/</link>
      <pubDate>Wed, 04 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/fall-in-love-with-sed/</guid>
      <description>Sed, it&amp;rsquo;s so powerful. I remember I struggled with finding practical uses for it when I did my LPIC-1 certification. But now I find myself using it several times a week. It is so powerful to edit multiple files at a time. I use it for work, but also for making changes to my entire second brain in Obsidian with one command.
Today I needed to update my /articles/ links to /zet/articles/ links because I&amp;rsquo;m restructuring my website.</description>
      <content:encoded><![CDATA[<p>Sed, it&rsquo;s so powerful. I remember I struggled with finding practical uses for it when I did my LPIC-1 certification. But now I find myself using it several times a week. It is so powerful to edit multiple files at a time. I use it for work, but also for making changes to my entire second brain in Obsidian with one command.</p>
<p>Today I needed to update my /articles/ links to /zet/articles/ links because I&rsquo;m restructuring my website. Here is the sed expression that is executed for every markdown file that is found by fd:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">sed -i <span class="s1">&#39;s/\/articles\//\/zet\/articles\//g&#39;</span> <span class="k">$(</span>fd .md<span class="k">)</span>
</span></span></code></pre></div><p>The result:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">diff --git a/content/zet/move-to-zet.md b/content/zet/move-to-zet.md
</span></span><span class="line"><span class="cl">index 1e37283..3b817e3 <span class="m">100644</span>
</span></span><span class="line"><span class="cl">--- a/content/zet/move-to-zet.md
</span></span><span class="line"><span class="cl">+++ b/content/zet/move-to-zet.md
</span></span><span class="line"><span class="cl">@@ -6,7 +6,7 @@ tags:
</span></span><span class="line"><span class="cl"> - Zettelkasten
</span></span><span class="line"><span class="cl"> ---
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">-I<span class="s1">&#39;ve transitioned my note taking system towards a Zettelkasten system. I still use directories for folders and make copious links, but more
</span></span></span><span class="line"><span class="cl"><span class="s1">often than not I put them in the larger generic 00-zettelkasten directory in my [Obsidian](/articles/obsidian-introduction/) vault.
</span></span></span><span class="line"><span class="cl"><span class="s1">+I&#39;</span>ve transitioned my note taking system towards a Zettelkasten system. I still use directories <span class="k">for</span> folders and make copious links, but more
</span></span><span class="line"><span class="cl">often than not I put them in the larger generic 00-zettelkasten directory in my <span class="o">[</span>Obsidian<span class="o">](</span>/zet/articles/obsidian-introduction/<span class="o">)</span> vault.
</span></span></code></pre></div><p>These sites are super useful to help you formulate your expressions:</p>
<p><a href="https://sed.js.org/">https://sed.js.org/</a></p>
<p><a href="https://regex101.com/">https://regex101.com/</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Application Insights: Telemetry Sampling</title>
      <link>https://mischavandenburg.com/zet/application-insights-sampling/</link>
      <pubDate>Tue, 03 Jan 2023 08:41:09 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/application-insights-sampling/</guid>
      <description>Telemetry is the collection of measurements or other data at remote points, and transmitting that data to a receiver for monitoring.
Sampling is used to reduce telemetry traffic and costs for storage and data in Application Insights.
For small and medium sized applications sampling is generally not necessary.
Advantages of sampling:
Throttling data when the application suddenly sends a high volume of telemetry in a short time This saves costs! Keeping a pricing tier quota Reduce network traffic from telemetry collection Three different kinds of sampling:</description>
      <content:encoded><![CDATA[<p>Telemetry is the collection of measurements or other data at remote points, and transmitting that data to a receiver for monitoring.</p>
<p>Sampling is used to reduce telemetry traffic and costs for storage and data in Application Insights.</p>
<p>For small and medium sized applications sampling is generally not necessary.</p>
<p>Advantages of sampling:</p>
<ul>
<li>Throttling data when the application suddenly sends a high volume of telemetry in a short time
<ul>
<li>This saves costs!</li>
</ul>
</li>
<li>Keeping a pricing tier quota</li>
<li>Reduce network traffic from telemetry collection</li>
</ul>
<p>Three different kinds of sampling:</p>
<ul>
<li>adaptive sampling
<ul>
<li>automatically adjusts volume of telemetry</li>
<li>from ASP.NET or Azure Functions</li>
<li>only for these two</li>
</ul>
</li>
<li>fixed-rate sampling
<ul>
<li>rate is set by the administrator</li>
<li>use when you have a clear idea of the appropriate sampling percentage</li>
<li>reduces volume from
<ul>
<li>ASP.NET or ASP.NET Core server</li>
<li>Java server</li>
<li>Python applications</li>
<li>User browsers</li>
</ul>
</li>
</ul>
</li>
<li>ingestion sampling
<ul>
<li>used when monthly quota is often met</li>
<li>reduces amount of processed and retained traffic by Application Insights
<ul>
<li>less processing = less cost</li>
<li>doesn&rsquo;t reduce telemetry traffic sent from the app</li>
<li>happens at Applications Insight service endpoint</li>
</ul>
</li>
<li>disabled if SDK samples telemetry</li>
<li>can set sampling rate without redeploying the app</li>
<li>only applies when no other sampling is in effect
<ul>
<li>supports all Application Insights SDK&rsquo;s</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Pipelines: Continuous Monitoring</title>
      <link>https://mischavandenburg.com/zet/pipelines-continuous-monitoring/</link>
      <pubDate>Tue, 03 Jan 2023 08:30:03 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/pipelines-continuous-monitoring/</guid>
      <description>This term can be confusing. Initially I thought it meant monitoring of the pipelines themselves. However, in the context of Azure Release Pipelines, continuous monitoring refers to something else.
Continuous monitoring leverages metrics from other services such as Application Insights. You can set up release gates based on these metrics. For example, you can set up a release gate to roll back the deployment if an alert is being fired for high CPU usage in the application.</description>
      <content:encoded><![CDATA[<p>This term can be confusing. Initially I thought it meant monitoring of the pipelines themselves. However, in the context of Azure Release Pipelines, continuous monitoring refers to something else.</p>
<p>Continuous monitoring leverages metrics from other services such as Application Insights. You can set up release gates based on these metrics. For example, you can set up a release gate to roll back the deployment if an alert is being fired for high CPU usage in the application.</p>
<p>You can set up several of these checks. If all these checks pass, the pipeline can proceed.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Distributed Tracing</title>
      <link>https://mischavandenburg.com/zet/distributed-tracing/</link>
      <pubDate>Tue, 03 Jan 2023 07:58:44 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/distributed-tracing/</guid>
      <description>Debugging is done using call stacks in monolithic applications. Nowadays it is more common to deploy an application using a microservices architecture. Microservices make it easier to update certain parts of the application, and allow for more frequent deployments.
Using microservices does have a disadvantage: you cannot use the local call stack for debugging, because calls are sent to different microservices.
Distributed tracing is an implementation of the call stack in the cloud.</description>
      <content:encoded><![CDATA[<p>Debugging is done using <a href="/zet/call-stacks/">call stacks</a> in monolithic applications. Nowadays it is more common to deploy an application using a microservices architecture. Microservices make it easier to update certain parts of the application, and allow for more frequent deployments.</p>
<p>Using microservices does have a disadvantage: you cannot use the local call stack for debugging, because calls are sent to different microservices.</p>
<p>Distributed tracing is an implementation of the call stack in the cloud. It is usually implemented by adding an agent, <a href="/zet/sdk/">SDK</a>, or library to the service. In Azure you can enable distributed tracing via Application Insights through auto-instrumentation or SDKs.</p>
<p><a href="https://learn.microsoft.com/en-us/azure/azure-monitor/app/transaction-diagnostics">Unified cross-component transaction diagnostics</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>What is a SDK?</title>
      <link>https://mischavandenburg.com/zet/sdk/</link>
      <pubDate>Tue, 03 Jan 2023 07:50:55 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/sdk/</guid>
      <description>A software development kit (SDK) is a set of tools provided by the manufacturer of (usually) a hardware platform, operating system (OS), or programming language.
SDKs contain all the tools you need to get started. They typically contain a compiler, a debugger and an API. But they can also contain documentation and testing tools.</description>
      <content:encoded><![CDATA[<p>A software development kit (SDK) is a set of tools provided by the manufacturer of (usually) a hardware platform, operating system (OS), or programming language.</p>
<p>SDKs contain all the tools you need to get started. They typically contain a compiler, a debugger and an API. But they can also contain documentation and testing tools.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Call Stacks</title>
      <link>https://mischavandenburg.com/zet/call-stacks/</link>
      <pubDate>Mon, 02 Jan 2023 21:11:26 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/call-stacks/</guid>
      <description>When you call a function, the system sets aside space in memory for the function to do its work. Those chunks are called &amp;ldquo;stack frames&amp;rdquo; or &amp;ldquo;function frames.&amp;rdquo;
These frames are arranged in a stack. The frame for the most recently called function is always at the top of the stack. When a new function is called, it becomes the active frame, and it is on top of the stack.</description>
      <content:encoded><![CDATA[<p>When you call a function, the system sets aside space in memory  for the function to do its work. Those chunks are called &ldquo;stack frames&rdquo; or &ldquo;function frames.&rdquo;</p>
<p>These frames are arranged in a stack. The frame for the most recently called function is always at the top of the stack. When a new function is called, it becomes the active frame, and it is on top of the stack.</p>
<p>The function that is actually doing something at the moment is on top of the stack and is known as the &ldquo;active frame.&rdquo;</p>
<p>When the function finishes its work, the frame is popped off of the stack. The frame in second place becomes the active frame. It had been paused in the meantime, and now it is active again, because it is on top.</p>
<p>Functions that are not on top, are not running.</p>
<p><a href="https://www.youtube.com/watch?v=aCPkszeKRa4">This video explains it well.</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Going to Publish Smaller, and More Often</title>
      <link>https://mischavandenburg.com/zet/move-to-zet/</link>
      <pubDate>Mon, 02 Jan 2023 20:52:50 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/move-to-zet/</guid>
      <description>I&amp;rsquo;ve transitioned my note taking system towards a Zettelkasten system. I still use directories for folders and make copious links, but more often than not I put them in the larger generic 00-zettelkasten directory in my Obsidian vault.
The concept of &amp;ldquo;atomic notes&amp;rdquo; is also very important in Zettelkasten methods. Notes should be small and concise.
Up until this point I&amp;rsquo;ve been publishing full articles on my blog. I came across Rob Muhlestein yesterday and I was very inspired by his setup and public zettelkasten.</description>
      <content:encoded><![CDATA[<p>I&rsquo;ve transitioned my note taking system towards a Zettelkasten system. I still use directories for folders and make copious links, but more often than not I put them in the larger generic 00-zettelkasten directory in my <a href="/zet/articles/obsidian-introduction/">Obsidian</a> vault.</p>
<p>The concept of &ldquo;atomic notes&rdquo; is also very important in Zettelkasten methods. Notes should be small and concise.</p>
<p>Up until this point I&rsquo;ve been publishing full articles on my blog. I came across <a href="https://github.com/rwxrob">Rob Muhlestein</a> yesterday and I was very inspired by his setup and public zettelkasten. I think I&rsquo;ll move to a similar approach. Still planning to write and publish full articles as well, but also including atomic notes and personal status updates.</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
