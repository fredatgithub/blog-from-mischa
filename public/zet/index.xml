<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Zettelkasten on Mischa van den Burg</title>
    <link>https://mischavandenburg.com/zet/</link>
    <description>Recent content in Zettelkasten on Mischa van den Burg</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 05 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://mischavandenburg.com/zet/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>All Articles</title>
      <link>https://mischavandenburg.com/zet/articles/</link>
      <pubDate>Sun, 05 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/articles/</guid>
      <description>These are long form articles.</description>
      <content:encoded><![CDATA[<p>These are long form articles.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Get a free 4 CPU 24GB Ram VM on from Oracle</title>
      <link>https://mischavandenburg.com/zet/free-oracle-vm/</link>
      <pubDate>Sat, 04 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/free-oracle-vm/</guid>
      <description>A few weeks ago someone gave me a tip. Oracle actually has a really good free tier offering.
You can host a 4CPU 24GB VM for free!
This is perfect for a lab environment.
I spent my evening creating the VM and setting up a kubernetes cluster from scratch.
Use this video to claim your free vm:
https://www.youtube.com/watch?v=NKc3k7xceT8</description>
      <content:encoded><![CDATA[<p>A few weeks ago someone gave me a tip. Oracle actually has a really good free tier offering.</p>
<p>You can host a 4CPU 24GB VM for free!</p>
<p>This is perfect for a lab environment.</p>
<p>I spent my evening creating the VM and setting up a kubernetes cluster from scratch.</p>
<p>Use this video to claim your free vm:</p>
<p><a href="https://www.youtube.com/watch?v=NKc3k7xceT8">https://www.youtube.com/watch?v=NKc3k7xceT8</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Setting up automated backups on my Arch Linux system with rsync and bash</title>
      <link>https://mischavandenburg.com/zet/arch-backup-setup-1/</link>
      <pubDate>Sat, 21 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/arch-backup-setup-1/</guid>
      <description>For the past few months I&amp;rsquo;ve been stuyding every hour of free time that I had. Now that I reached my certification goals for now, I finally had some time to do a chore I had been meaning to do for a long time.
My Arch Linux system is fully encrypted, and I make backups. But I was still doing it a bit haphazardly, usually every Friday.
I wanted to automate this for a long time now, but I never got round to it.</description>
      <content:encoded><![CDATA[<p>For the past few months I&rsquo;ve been stuyding every hour of free time that I had. Now that I reached my certification goals for now, I finally had some time to do a chore I had been meaning to do for a long time.</p>
<p>My Arch Linux system is fully encrypted, and I make backups. But I was still doing it a bit haphazardly, usually every Friday.</p>
<p>I wanted to automate this for a long time now, but I never got round to it. Today I made the first steps, but it is still in progress.</p>
<p>Naturally, I could use a tool like Timeshift or something similar to schedule my backups. However, I want to do it myself using rsync because I want to fully understand what I am backing up, when, and where. Rsync is also used in our environment at work, so I assume it is more common in enterprise and production environments.</p>
<h2 id="full-system-backup">full system backup</h2>
<p>Before I was making a full system backup every Friday using this command:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">sudo rsync -aAXH --info<span class="o">=</span>stats1,progress2 --exclude<span class="o">={</span><span class="s2">&#34;/dev/*&#34;</span>,<span class="s2">&#34;/proc/*&#34;</span>,<span class="s2">&#34;/sys/*&#34;</span>,<span class="s2">&#34;/tmp/*&#34;</span>,<span class="s2">&#34;/run/*&#34;</span>,<span class="s2">&#34;/mnt/*&#34;</span>,<span class="s2">&#34;/media/*&#34;</span>,<span class="s2">&#34;/lost+found&#34;</span>,<span class="s2">&#34;/home/*/.cache/*&#34;</span>,<span class="s2">&#34;/data-hdd/&#34;</span>,<span class="s2">&#34;/games/&#34;</span>,<span class="s2">&#34;/var/lib/docker/*&#34;</span>,<span class="s2">&#34;/home/mischa/music/*&#34;</span>,<span class="s2">&#34;/swapfile&#34;</span>, <span class="s2">&#34;/data-hdd2/&#34;</span>, <span class="s2">&#34;/data-hdd3/&#34;</span><span class="o">}</span> / /data-hdd/backups/arch-beast/01-01-23
</span></span></code></pre></div><p>This command creates a full backup of my entire root filesystem, and it should be possible to restore my entire system by just reversing the target and destination in the end.</p>
<p>However, as I was coming up with my new strategy, I thought this was overkill.</p>
<h2 id="slimming-down">slimming down</h2>
<p>All I really need to back up is my home directory and it would be nice to have my /etc directory backed up as well.</p>
<p>So I wrote a simple shell script to do this:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="cp">#!/bin/bash
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="nv">BACKUPS_DESTINATION</span><span class="o">=</span><span class="s2">&#34;/data-hdd/backups/arch-beast&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># format:</span>
</span></span><span class="line"><span class="cl"><span class="c1"># rsync -a --delete --quiet /path/to/backup /location/of/backup</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># stop the script if an error occurs</span>
</span></span><span class="line"><span class="cl"><span class="nb">set</span> -e
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">rsync -a --delete --quiet --exclude<span class="o">=</span><span class="s2">&#34;{&#34;</span>/home/*/.cache/*<span class="s2">&#34;}&#34;</span> /home/mischa <span class="nv">$BACKUPS_DESTINATION</span>/home
</span></span><span class="line"><span class="cl">rsync -a --delete --quiet /etc <span class="nv">$BACKUPS_DESTINATION</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;Made backups on: </span><span class="k">$(</span>date<span class="k">)</span><span class="s2">&#34;</span> &gt;&gt; /var/log/backup.log
</span></span></code></pre></div><p>-a flag from man page:</p>
<p><em>&ldquo;This  is  equivalent to -rlptgoD.  It is a quick way of saying you want recursion and want to preserve almost everything.&rdquo;</em></p>
<p>&ndash;delete: means files deleted on the source are to be deleted on the backup as well</p>
<h2 id="automation">automation</h2>
<p>I have a few scripts running in cronjobs on my system. I have a goal of putting them all in systemd timers, but I haven&rsquo;t gotten round to it yet. For now, I will just add my backup scripts to my existing cronjobs setup.</p>
<p>To make my backups every day, I added this to my crontab:</p>
<p><code>0 12 * * * /bin/bash /home/mischa/git/lab/bash/backup</code></p>
<p>Every day it will make a backup to the same directory and update the changed files, or delete the files I deleted from my system.</p>
<p>I also wanted to have a weekly backup happening on Monday.</p>
<p>I will make a more elaborate script to make a weekly directory, and rotate it with a new directory every week. But for now, I just chose a quick solution by creating a weekly version of my script and running it every Monday.</p>
<p>The only difference is the path:</p>
<p><code>BACKUPS_DESTINATION=&quot;/data-hdd/backups/arch-beast/weekly&quot;</code></p>
<p>In the crontab:</p>
<p><code>0 10 * * 1 /bin/bash /home/mischa/git/lab/bash/backup-weekly</code></p>
<h2 id="to-do">to do</h2>
<ul>
<li>set up weekly backup in the same script</li>
<li>create error handling and improve logging</li>
<li>set up in systemd timers instead of crontab</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>I passed the AZ-400 DevOps Expert today</title>
      <link>https://mischavandenburg.com/zet/passed-az-400/</link>
      <pubDate>Sat, 14 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/passed-az-400/</guid>
      <description>I&amp;rsquo;m typing this 30 minutes after I passed my AZ-400 exam. I&amp;rsquo;m sitting in a lovely cafe on Leidseplein in Amsterdam and feel relieved. Another significant certification bites the dust. This one took about 70 hours of study.
I started preparing immediately after passing my AZ-104 exam, which was a good move. The AZ-400 requires you to know many details about Azure services and how to access them. For example, Shared Access Signatures are only used for accessing storage accounts, but they came up quite often as alternative answers to the questions.</description>
      <content:encoded><![CDATA[<p>I&rsquo;m typing this 30 minutes after I passed my AZ-400 exam. I&rsquo;m sitting in a lovely cafe on Leidseplein in Amsterdam and feel relieved. Another significant certification bites the dust. This one took about 70 hours of study.</p>
<p>I started preparing immediately after passing my AZ-104 exam, which was a good move. The AZ-400 requires you to know many details about Azure services and how to access them. For example, Shared Access Signatures are only used for accessing storage accounts, but they came up quite often as alternative answers to the questions.</p>
<p>The exam itself was difficult, but the AZ-104 was harder. The AZ-104 exam was more challenging because the questions were complicated and required you to simultaneously balance many different factors in the mind. The AZ-400 was difficult because the answer alternatives that are provided are incredibly similar to each other, and they make you very insecure about what the right choice might be. As a result, I changed my answers many times.</p>
<p>I will do another study guide for this certification soon and publish my notes and Anki deck too. Now it&rsquo;s time to celebrate and relax a little.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Azure DevOps Personal Access Tokens are always for authenticating into ADO</title>
      <link>https://mischavandenburg.com/zet/azure-personal-access-tokens/</link>
      <pubDate>Fri, 13 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/azure-personal-access-tokens/</guid>
      <description>The PAT (Personal Access Token) often comes up during practice tests for the AZ-400.
One way to remember when to use a PAT is that these are only for authenticating into Azure DevOps, never to external services.
For example, you might get a question on connecting your Azure DevOps project with a GitHub account from Azure DevOps, and PAT will show up as one of the alternative answers. By remembering that PATs are only for authenticating into ADO, you can elminate this alternative, and make your choice easier.</description>
      <content:encoded><![CDATA[<p>The PAT (Personal Access Token) often comes up during practice tests for the AZ-400.</p>
<p>One way to remember when to use a PAT is that these are only for authenticating <strong>into</strong> Azure DevOps, never to external services.</p>
<p>For example, you might get a question on connecting your Azure DevOps project with a GitHub account from Azure DevOps, and PAT will show up as one of the alternative answers. By remembering that PATs are only for authenticating into ADO, you can elminate this alternative, and make your choice easier.</p>
<p>Personal Access Tokens are an alternative to passwords but should be treated in exactly the same way.</p>
<p><a href="https://learn.microsoft.com/en-us/azure/devops/organizations/accounts/use-personal-access-tokens-to-authenticate?view=azure-devops&amp;tabs=Windows">https://learn.microsoft.com/en-us/azure/devops/organizations/accounts/use-personal-access-tokens-to-authenticate?view=azure-devops&amp;tabs=Windows</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>The Pomodoro technique has won me over</title>
      <link>https://mischavandenburg.com/zet/pomodoro/</link>
      <pubDate>Fri, 13 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/pomodoro/</guid>
      <description>I did a lot of studying last year, and I achieved a few tough certifications. I&amp;rsquo;ve always been good at studying and never struggled with getting decent grades in university. As a result, I never felt the need to use particular techniques to pass my tests. However, now that I need to do my studies combined with a full-time job, I did some optimization and looked into study techniques.
One technique I&amp;rsquo;ve become very fond of is the Pomodoro Technique.</description>
      <content:encoded><![CDATA[<p>I did a lot of studying last year, and I achieved a few tough certifications. I&rsquo;ve always been good at studying and never struggled with getting decent grades in university. As a result, I never felt the need to use particular techniques to pass my tests. However, now that I need to do my studies combined with a full-time job, I did some optimization and looked into study techniques.</p>
<p>One technique I&rsquo;ve become very fond of is the Pomodoro Technique. I don&rsquo;t have any problems focusing for long periods, but I still decided to try it. I use the standard 25-minute study with a 5-minute break routine, and after four cycles, I take a 30-minute break.</p>
<p>The Pomodoro technique has been a way to force myself to take breaks, which I wasn&rsquo;t used to. I used to chip away at a specific task for hours. However, I discovered that when I take a break, walk around for five minutes, and apply myself to the task again, my mind is in a fresh state and much more receptive to the information. Perhaps the time I spend studying after a break is actually more productive because the mind had a little rest.</p>
<p>The technique also pushed my limits a bit more. I study more hours a day, considering that I also work full time. There is this moment where I want to quit studying, but I ask myself, &ldquo;do I have another Pomodoro in me?&rdquo;</p>
<p>Now that I&rsquo;ve gotten used to breaking things up into 25-minute chunks of time, I started using the Pomodoro technique for other areas in life as well, such as blog writing or coding projects.</p>
<p>You can use any tool you like to start using the Pomodoro technique and pick any break schedule that suits you. I&rsquo;ll link some resources below. All you need is some sort of timer. You can use a timer on your computer or a physical timer. I use the Forest app on my iPhone because it integrates with the iOs &ldquo;do not disturb&rdquo; and &ldquo;focus&rdquo; modes, so  I don&rsquo;t get any distracting notifications when I&rsquo;m on a Pomodoro.</p>
<p><a href="https://science.nichd.nih.gov/confluence/display/newsletter/2020/05/07/The+Pomodoro+Technique%3A+An+Effective+Time+Management+Tool">https://science.nichd.nih.gov/confluence/display/newsletter/2020/05/07/The+Pomodoro+Technique%3A+An+Effective+Time+Management+Tool</a></p>
<p><a href="https://www.youtube.com/watch?v=5WRO79zuJ4U">https://www.youtube.com/watch?v=5WRO79zuJ4U</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Using parameter expansion as search and replace</title>
      <link>https://mischavandenburg.com/zet/slash-syntax-replace/</link>
      <pubDate>Tue, 10 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/slash-syntax-replace/</guid>
      <description>Last modified: 2023-01-10
In this evening&amp;rsquo;s studies I came across this bash script in a tutorial by Rob Muhlenstein:
!#/bin/bash echo -e ${PATH//:/\\n} I could not make heads or tails of all these slashes and curly braces, since the output clearly indicated that search and replacement was being performed. I&amp;rsquo;m used to the sed / vim syntax: s/foo/bar
After some research I learned that &amp;lsquo;//&amp;rsquo; is a global search and replace syntax of several text processing programs.</description>
      <content:encoded><![CDATA[<p><em>Last modified: 2023-01-10</em></p>
<p>In this evening&rsquo;s studies I came across this bash script in a tutorial by Rob Muhlenstein:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">!#/bin/bash
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> -e <span class="si">${</span><span class="nv">PATH</span><span class="p">//:/</span><span class="se">\\</span><span class="nv">n</span><span class="si">}</span>
</span></span></code></pre></div><p>I could not make heads or tails of all these slashes and curly braces, since the output clearly indicated that search and replacement was being performed. I&rsquo;m used to the sed / vim syntax: <code>s/foo/bar</code></p>
<p>After some research I learned that &lsquo;//&rsquo; is a global search and replace syntax of several text processing programs. It is known as parameter expansion in bash.</p>
<p>Example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nv">foo</span><span class="o">=</span><span class="s2">&#34;1234567890&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;</span><span class="si">${</span><span class="nv">foo</span><span class="p">//[0-9]/x</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span></code></pre></div><p>This replaces all the digits in the $foo variable with &lsquo;x&rsquo;, so the output would be xxxxxxxxxx</p>
<p>To do this with sed, you would do:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;</span><span class="nv">$foo</span><span class="s2">&#34;</span> <span class="p">|</span> sed <span class="s1">&#39;s/[0-9]/x/g&#39;</span>
</span></span></code></pre></div><p>For more info:</p>
<p><code>man bash</code></p>
<p><code>/parameter expansion</code></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Automatically adding my recent blog posts to my GitHub Readme</title>
      <link>https://mischavandenburg.com/zet/adding-posts-github-readme/</link>
      <pubDate>Mon, 09 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/adding-posts-github-readme/</guid>
      <description>My friend gave me a nice tip for customizing the readme on my personal GitHub page. I discovered there is a whole world of plugins and customizations out there.
I set up this one for my GitHub homepage. It uses a workflow to update the readme in my personal GitHub repo with the most recent posts from this blog, based on the RSS feed. Neat!
It was very easy to set up.</description>
      <content:encoded><![CDATA[<p>My friend gave me a nice tip for customizing the readme on my personal GitHub page. I discovered there is a whole world of plugins and customizations out there.</p>
<p>I set up <a href="https://github.com/abhisheknaiidu/awesome-github-profile-readme">this one</a> for my GitHub homepage. It uses a workflow to update the readme in my personal GitHub repo with the most recent posts from this blog, based on the RSS feed. Neat!</p>
<p>It was very easy to set up. If you don&rsquo;t have your own blog, you could configure it with a different RSS feed. Hacker News for example.</p>
<p><a href="https://github.com/gautamkrishnar/blog-post-workflow">https://github.com/gautamkrishnar/blog-post-workflow</a></p>
<p><a href="https://github.com/abhisheknaiidu/awesome-github-profile-readme">https://github.com/abhisheknaiidu/awesome-github-profile-readme</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Back to Bas(h)ics: leaving zsh for now</title>
      <link>https://mischavandenburg.com/zet/back-to-bashics/</link>
      <pubDate>Sun, 08 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/back-to-bashics/</guid>
      <description>I&amp;rsquo;ve used zsh for nearly two years now. I have a custom setup with autocompletion and a good looking prompt.
Recently I&amp;rsquo;ve been diving deeper into bash scripting, following tutorials by rwxrob. He emphasizes all the time that it is much better to stick to bash instead of zsh.
Advantages of using bash:
the default Linux shell available on any Linux system full documentation available anywhere at all times with man bash free software less dependent on external plugins and configurations more portable practice by working on the command line The fact that working on the commandline is already coding convinced me to leave my beloved customized prompt behind (for now) and go back to the basics.</description>
      <content:encoded><![CDATA[<p>I&rsquo;ve used zsh for nearly two years now. I have a custom setup with autocompletion and a good looking prompt.</p>
<p>Recently I&rsquo;ve been diving deeper into bash scripting, following tutorials by rwxrob. He emphasizes all the time that it is much better to stick to bash instead of zsh.</p>
<p>Advantages of using bash:</p>
<ul>
<li>the default Linux shell</li>
<li>available on any Linux system</li>
<li>full documentation available anywhere at all times with <code>man bash</code></li>
<li>free software</li>
<li>less dependent on external plugins and configurations</li>
<li>more portable</li>
<li>practice by working on the command line</li>
</ul>
<p>The fact that <a href="/content/zet/bash-cmdline-is-coding.md">working on the commandline is already coding</a> convinced me to leave my beloved customized prompt behind (for now) and go back to the basics.</p>
<p>I want to improve my bash scripting, and working in the bash shell will improve that just by virtue of doing my daily tasks on the command line.</p>
<p>Also I noticed I&rsquo;ve gotten used to zsh&rsquo;s excellent autocompletion and menu navigation. When I log in to servers at work, there is always this little moment of &ldquo;oh, I don&rsquo;t have that here&rdquo;. I want to get better at bash so I&rsquo;m not dependent on these external crutches anymore.</p>
<p>Also, I&rsquo;m going to port my zsh configuration to bash. My current zsh configuration loads a bunch of plugins, and it is more of a hassle to get set up on a new system.</p>
<p>I want to be able to pull my dotfiles repo and do very few steps to configure my environment.</p>
<p>But I&rsquo;m going to miss that good-looking prompt with all the lovely icons!</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>How to build and deploy a Docker container to an Azure VM using Azure Pipelines</title>
      <link>https://mischavandenburg.com/zet/docker-to-azure-vm/</link>
      <pubDate>Sun, 08 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/docker-to-azure-vm/</guid>
      <description>I wanted to build an application from a Dockerfile and deploy it to a VM. I used a default Svelte setup as an example app.
Naturally, Azure prefers that you deploy containers to services such as Azure Container Instances or App Services, so they don&amp;rsquo;t provide modules for the pipelines to deploy to docker servers as far as I could tell.
I searched for a long time but I could not find a solution.</description>
      <content:encoded><![CDATA[<p>I wanted to build an application from a Dockerfile and deploy it to a VM. I used a default Svelte setup as an example app.</p>
<p>Naturally, Azure prefers that you deploy containers to services such as Azure Container Instances or App Services, so they don&rsquo;t provide modules for the pipelines to deploy to docker servers as far as I could tell.</p>
<p>I searched for a long time but I could not find a solution. In the end I just ran shell commands from the pipeline to run the container on on the server.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">steps</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">script</span><span class="p">:</span><span class="w"> </span><span class="p">|</span><span class="sd">
</span></span></span><span class="line"><span class="cl"><span class="sd">      sudo docker stop svelte-test
</span></span></span><span class="line"><span class="cl"><span class="sd">      sudo docker rm svelte-test
</span></span></span><span class="line"><span class="cl"><span class="sd">      sudo docker run --name svelte-test -p 8080:80 -d mischavandenburg/svelte-test:$(Build.BuildId)</span><span class="w">      
</span></span></span></code></pre></div><p>You can find the full pipeline code, the app and Dockerfile in my lab repo:</p>
<p><a href="https://github.com/mischavandenburg/lab/tree/main/azure-pipelines/docker-to-azure-vm">https://github.com/mischavandenburg/lab/tree/main/azure-pipelines/docker-to-azure-vm</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>How to deploy to a Linux VM in Azure with Azure Pipelines</title>
      <link>https://mischavandenburg.com/zet/azure-pipelines-deploy-vm/</link>
      <pubDate>Sun, 08 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/azure-pipelines-deploy-vm/</guid>
      <description>To reach a VM from Azure Pipelines, you need to set up an environment.
Create your Linux VM in Azure.
In Azure DevOps, click envirnoments, new, and select the Virtual Machine option.
A command is generated for you. SSH into your VM and run the command.
Now the VM should show up under environments in Azure DevOps.
Set up a repo with an azure-pipelines.yml with these contents to test. under environment, set the same name as you did in Azure DevOps for your environment.</description>
      <content:encoded><![CDATA[<p>To reach a VM from Azure Pipelines, you need to set up an environment.</p>
<p>Create your Linux VM in Azure.</p>
<p>In Azure DevOps, click envirnoments, new, and select the Virtual Machine option.</p>
<p><img loading="lazy" src="/env1.png" type="" alt=""  /></p>
<p>A command is generated for you. SSH into your VM and run the command.</p>
<p><img loading="lazy" src="/env2.png" type="" alt=""  /></p>
<p>Now the VM should show up under environments in Azure DevOps.</p>
<p>Set up a repo with an azure-pipelines.yml with these contents to test. under <code>environment</code>, set the same name as you did in Azure DevOps for your environment.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">trigger</span><span class="p">:</span><span class="w"> 
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="l">main</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">pool</span><span class="p">:</span><span class="w"> 
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="nt">vmImage</span><span class="p">:</span><span class="w"> </span><span class="l">ubuntu-latest</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">jobs</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="nt">deployment</span><span class="p">:</span><span class="w"> </span><span class="l">VMDeploy</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">displayName</span><span class="p">:</span><span class="w"> </span><span class="l">Deploy to VM</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">environment</span><span class="p">:</span><span class="w"> 
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">dev</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="nt">resourceType</span><span class="p">:</span><span class="w"> </span><span class="l">VirtualMachine</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">strategy</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">     </span><span class="nt">runOnce</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">deploy</span><span class="p">:</span><span class="w">   
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">steps</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span>- <span class="nt">script</span><span class="p">:</span><span class="w"> </span><span class="l">echo &#34;Hello world&#34;</span><span class="w">
</span></span></span></code></pre></div><p>You can see it when the deploy runs on the VM:</p>
<p><img loading="lazy" src="/env3.png" type="" alt=""  /></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Deploying a Linux VM to Azure with Terraform</title>
      <link>https://mischavandenburg.com/zet/terraform-linux-vm/</link>
      <pubDate>Sat, 07 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/terraform-linux-vm/</guid>
      <description>For a project I&amp;rsquo;m setting up my environment with Terraform.
I used this tutorial, but modified the code to make it simpler and easier to understand for beginners. The original uses a random module to generate random names, and generates a new SSH key. Also, this tutorial uses expensive VM tiers and Premium storage, which are not necessary when you are learning.
I also thought the SSH configuration was overcomplicated. My version just takes an SSH keypair stored at ~/.</description>
      <content:encoded><![CDATA[<p>For a project I&rsquo;m setting up my environment with Terraform.</p>
<p>I used <a href="https://learn.microsoft.com/en-us/azure/virtual-machines/linux/quick-create-terraform">this tutorial</a>, but modified the code to make it simpler and easier to understand for beginners. The original uses a random module to generate random names, and generates a new SSH key. Also, this tutorial uses expensive VM tiers and Premium storage, which are not necessary when you are learning.</p>
<p>I also thought the SSH configuration was overcomplicated. My version just takes an SSH keypair stored at <code>~/.ssh/id_rsa.pub</code></p>
<p>To run:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-hcl" data-lang="hcl"><span class="line"><span class="cl"><span class="k">terraform</span> <span class="k">init</span>
</span></span><span class="line"><span class="cl"><span class="k">terraform</span> <span class="k">plan</span>
</span></span><span class="line"><span class="cl"><span class="k">terraform</span> <span class="k">apply</span>
</span></span></code></pre></div><p>The scripts prints the public IP of the newly created VM. You should be able to SSH to it:</p>
<p><code>ssh azureuser@the_printed_ip_address</code></p>
<p>You can find the code in <a href="https://github.com/mischavandenburg/lab/tree/main/terraform/azure-simple-linux-vm">my &ldquo;lab&rdquo; repo on GitHub.</a></p>
<p><a href="https://github.com/mischavandenburg/lab/tree/main/terraform/azure-simple-linux-vm">https://github.com/mischavandenburg/lab/tree/main/terraform/azure-simple-linux-vm</a></p>
<p><a href="https://learn.microsoft.com/en-us/azure/virtual-machines/linux/quick-create-terraform">https://learn.microsoft.com/en-us/azure/virtual-machines/linux/quick-create-terraform</a></p>
<p><a href="https://learn.microsoft.com/en-us/azure/developer/terraform/authenticate-to-azure?source=recommendations&amp;tabs=bash#authenticate-to-azure-via-a-microsoft-account">https://learn.microsoft.com/en-us/azure/developer/terraform/authenticate-to-azure?source=recommendations&amp;tabs=bash#authenticate-to-azure-via-a-microsoft-account</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>How to follow symbolic links while searching with Telescope in neovim</title>
      <link>https://mischavandenburg.com/zet/neovim-telescope-follow-symlinks/</link>
      <pubDate>Fri, 06 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/neovim-telescope-follow-symlinks/</guid>
      <description>I use the Obsidian app, but I mostly write and search my notes with neovim. I added my zet directory from this blog repo into the Obsidian vault as a symbolic link, but I soon discovered that these files were not being searched.
Telescope.nvim uses ripgrep (rg) to do the live grepping in its search, and ripgrep does not follow symbolic links by default. You need to pass the -L flag to it.</description>
      <content:encoded><![CDATA[<p>I use the <a href="/zet/articles/obsidian-introduction/">Obsidian</a> app, but I mostly write and search my notes with neovim. I added my zet directory from this blog repo into the Obsidian vault as a symbolic link, but I soon discovered that these files were not being searched.</p>
<p>Telescope.nvim uses ripgrep (rg) to do the live grepping in its search, and ripgrep does not follow symbolic links by default. You need to pass the -L flag to it.</p>
<p>To pass the -L flag, and some other flags, I added the following to my telescope config file:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-lua" data-lang="lua"><span class="line"><span class="cl"><span class="c1">-- Custom ripgrep configuration:</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kd">local</span> <span class="n">telescope</span> <span class="o">=</span> <span class="n">require</span><span class="p">(</span><span class="s2">&#34;telescope&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="kd">local</span> <span class="n">telescopeConfig</span> <span class="o">=</span> <span class="n">require</span><span class="p">(</span><span class="s2">&#34;telescope.config&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">-- Clone the default Telescope configuration</span>
</span></span><span class="line"><span class="cl"><span class="kd">local</span> <span class="n">vimgrep_arguments</span> <span class="o">=</span> <span class="p">{</span> <span class="n">unpack</span><span class="p">(</span><span class="n">telescopeConfig.values</span><span class="p">.</span><span class="n">vimgrep_arguments</span><span class="p">)</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">-- I want to search in hidden/dot files.</span>
</span></span><span class="line"><span class="cl"><span class="n">table.insert</span><span class="p">(</span><span class="n">vimgrep_arguments</span><span class="p">,</span> <span class="s2">&#34;--hidden&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1">-- I don&#39;t want to search in the `.git` directory.</span>
</span></span><span class="line"><span class="cl"><span class="n">table.insert</span><span class="p">(</span><span class="n">vimgrep_arguments</span><span class="p">,</span> <span class="s2">&#34;--glob&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">table.insert</span><span class="p">(</span><span class="n">vimgrep_arguments</span><span class="p">,</span> <span class="s2">&#34;!**/.git/*&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">-- I want to follow symbolic links</span>
</span></span><span class="line"><span class="cl"><span class="n">table.insert</span><span class="p">(</span><span class="n">vimgrep_arguments</span><span class="p">,</span> <span class="s2">&#34;-L&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">telescope.setup</span><span class="p">({</span>
</span></span><span class="line"><span class="cl">	<span class="n">defaults</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="c1">-- `hidden = true` is not supported in text grep commands.</span>
</span></span><span class="line"><span class="cl">		<span class="n">vimgrep_arguments</span> <span class="o">=</span> <span class="n">vimgrep_arguments</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="p">},</span>
</span></span><span class="line"><span class="cl">	<span class="n">pickers</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="n">find_files</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">			<span class="c1">-- `hidden = true` will still show the inside of `.git/` as it&#39;s not `.gitignore`d.</span>
</span></span><span class="line"><span class="cl">			<span class="n">find_command</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&#34;rg&#34;</span><span class="p">,</span> <span class="s2">&#34;--files&#34;</span><span class="p">,</span> <span class="s2">&#34;--hidden&#34;</span><span class="p">,</span> <span class="s2">&#34;--glob&#34;</span><span class="p">,</span> <span class="s2">&#34;!**/.git/*&#34;</span><span class="p">,</span> <span class="s2">&#34;-L&#34;</span> <span class="p">},</span>
</span></span><span class="line"><span class="cl">		<span class="p">},</span>
</span></span><span class="line"><span class="cl">	<span class="p">},</span>
</span></span><span class="line"><span class="cl"><span class="p">})</span>
</span></span></code></pre></div><p>Based on the configuration examples found on the project&rsquo;s GitHub page.</p>
<p><a href="https://github.com/nvim-telescope/telescope.nvim">https://github.com/nvim-telescope/telescope.nvim</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Attaching the Ansible Language Server to yaml files in neovim (LSP)</title>
      <link>https://mischavandenburg.com/zet/ansible-lsp-fix/</link>
      <pubDate>Thu, 05 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/ansible-lsp-fix/</guid>
      <description>When you have an Ansible language server installed, you might find that your yaml LSP will attach to your current buffer, but the ansible language server won&amp;rsquo;t attach.
You can fix this by setting the correct file type for the current buffer:
:set ft=yaml.ansible
You could also adjust the Ansible LSP so it attaches to all yaml files. However, this does not work out for me, because I edit different yaml files for different purposes every day.</description>
      <content:encoded><![CDATA[<p>When you have an Ansible language server installed, you might find that your yaml LSP will attach to your current buffer, but the ansible language server won&rsquo;t attach.</p>
<p>You can fix this by setting the correct file type for the current buffer:</p>
<p><code>:set ft=yaml.ansible</code></p>
<p>You could also adjust the Ansible LSP so it attaches to all yaml files. However, this does not work out for me, because I edit different yaml files for different purposes every day. Not all yaml files are to be used with Ansible.</p>
<p>There is logic for the Ansible language server to figure out if you are working on Ansible yaml files based on the directory structure you&rsquo;re working in.</p>
<p>So setting the filetype when I needed works well for me.</p>
<p><a href="https://www.reddit.com/r/neovim/comments/tbd7g0/lsp_ansiblels_wont_attach_anymore/">https://www.reddit.com/r/neovim/comments/tbd7g0/lsp_ansiblels_wont_attach_anymore/</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>How to install the Openstack CLI on Linux</title>
      <link>https://mischavandenburg.com/zet/install-openstack-cli/</link>
      <pubDate>Thu, 05 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/install-openstack-cli/</guid>
      <description>Make sure to have pip installed.
Run pip install python-openstackclient
Pip will install a binary called &amp;ldquo;openstack&amp;rdquo; in ~/.local/bin
If the openstack command is not available in your session, you might need to add it to your PATH:
export PATH=&amp;quot;$HOME/.local/bin:$PATH&amp;quot;
Add this to your ~/.zshrc or ~/.bashrc to make sure this happens for each shell session.
Don&amp;rsquo;t forget to source your updated ~/.zshrc if you chose to add it:
source ~/.</description>
      <content:encoded><![CDATA[<p>Make sure to have pip installed.</p>
<p>Run <code>pip install python-openstackclient</code></p>
<p>Pip will install a binary called &ldquo;openstack&rdquo; in ~/.local/bin</p>
<p>If the openstack command is not available in your session, you might need to add it to your PATH:</p>
<p><code>export PATH=&quot;$HOME/.local/bin:$PATH&quot;</code></p>
<p>Add this to your ~/.zshrc or ~/.bashrc to make sure this happens for each shell session.</p>
<p>Don&rsquo;t forget to source your updated ~/.zshrc if you chose to add it:</p>
<p><code>source ~/.zshrc</code></p>
<p><a href="https://docs.openstack.org/newton/user-guide/common/cli-install-openstack-command-line-clients.html">https://docs.openstack.org/newton/user-guide/common/cli-install-openstack-command-line-clients.html</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>How to Reset a VM Root Password using the Openstack CLI</title>
      <link>https://mischavandenburg.com/zet/openstack-root-password/</link>
      <pubDate>Thu, 05 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/openstack-root-password/</guid>
      <description> Download the Openstack RC file from the Openstack portal. Click your username in the top right corner to find it. Source the RC file to make the environment variables avaialable to your current session: source ~/my_openstack.sh Find the instance ID of your VM from the portal. Run openstack server set --root-password be3xxxx5-8348-418b-xxxb-c4xxxx575cd You will be prompted for the new password which will be set on the virtual machine. </description>
      <content:encoded><![CDATA[<ol>
<li>Download the Openstack RC file from the Openstack portal. Click your username in the top right corner to find it.</li>
<li>Source the RC file to make the environment variables avaialable to your current session: <code>source ~/my_openstack.sh</code></li>
<li>Find the instance ID of your VM from the portal.</li>
<li>Run <code>openstack server set --root-password be3xxxx5-8348-418b-xxxb-c4xxxx575cd</code></li>
<li>You will be prompted for the new password which will be set on the virtual machine.</li>
</ol>
]]></content:encoded>
    </item>
    
    <item>
      <title>How to run installed pip packages as binaries</title>
      <link>https://mischavandenburg.com/zet/run-installed-pip-packages/</link>
      <pubDate>Thu, 05 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/run-installed-pip-packages/</guid>
      <description>When you install a pip package which is meant to be run from the command line as a command, you might find that it is not available to you after installation.
If this happens, it might be that the path is missing from your PATH variable. Therefore, the shell does not source these binaries when initiated, and does not know that these executables exist.
You can find the location of your binaries by running pip show package_name</description>
      <content:encoded><![CDATA[<p>When you install a pip package which is meant to be run from the command line as a command, you might find that it is not available to you after installation.</p>
<p>If this happens, it might be that the path is missing from your PATH variable. Therefore, the shell does not source these binaries when initiated, and does not know that these executables exist.</p>
<p>You can find the location of your binaries by running <code>pip show package_name</code></p>
<p>Usually the binaries will be located in ~/.local/bin on a UNIX based system.</p>
<p>To add this to your path, run:</p>
<p><code>export PATH=&quot;$HOME/.local/bin:$PATH&quot;</code></p>
<p>Add this to your ~/.zshrc or ~/.bashrc to make sure this happens for each shell session.</p>
<p>Don&rsquo;t forget to source your updated ~/.zshrc if you chose to add it:</p>
<p><code>source ~/.zshrc</code></p>
<p><a href="https://stackoverflow.com/questions/29980798/where-does-pip-install-its-packages">https://stackoverflow.com/questions/29980798/where-does-pip-install-its-packages</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Working on the command line is already coding</title>
      <link>https://mischavandenburg.com/zet/bash-cmdline-is-coding/</link>
      <pubDate>Thu, 05 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/bash-cmdline-is-coding/</guid>
      <description>Rob Muhlenstein makes an interesting point that using bash on the command line is already coding. When you are running commands in the terminal, you are coding one line at a time.
When you put these commands in a file you have a bash script. Therefore, he argues that bash should be your first language.
I think this is such an interesting point. I&amp;rsquo;ve been using Linux and working on the command line for years but it never dawned on me that I, in fact, was coding while working on the command line.</description>
      <content:encoded><![CDATA[<p>Rob Muhlenstein makes an interesting point that using bash on the command line is already coding. When you are running commands in the terminal, you are coding one line at a time.</p>
<p>When you put these commands in a file you have a bash script. Therefore, he argues that bash should be your first language.</p>
<p>I think this is such an interesting point. I&rsquo;ve been using Linux and working on the command line for years but it never dawned on me that I, in fact, was coding while working on the command line. However, when I was writing bash scripts, I did consider myself to be coding. There is literally no difference. A bash script is just a string of commands that you would enter manually anyway.</p>
<p><a href="https://rwx.gg/">https://rwx.gg/</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Fall in love with sed.</title>
      <link>https://mischavandenburg.com/zet/fall-in-love-with-sed/</link>
      <pubDate>Wed, 04 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://mischavandenburg.com/zet/fall-in-love-with-sed/</guid>
      <description>Sed, it&amp;rsquo;s so powerful. I remember I struggled with finding practical uses for it when I did my LPIC-1 certification. But now I find myself using it several times a week. It is so powerful to edit multiple files at a time. I use it for work, but also for making changes to my entire second brain in Obsidian with one command.
Today I needed to update my /articles/ links to /zet/articles/ links because I&amp;rsquo;m restructuring my website.</description>
      <content:encoded><![CDATA[<p>Sed, it&rsquo;s so powerful. I remember I struggled with finding practical uses for it when I did my LPIC-1 certification. But now I find myself using it several times a week. It is so powerful to edit multiple files at a time. I use it for work, but also for making changes to my entire second brain in Obsidian with one command.</p>
<p>Today I needed to update my /articles/ links to /zet/articles/ links because I&rsquo;m restructuring my website. Here is the sed expression that is executed for every markdown file that is found by fd:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">sed -i <span class="s1">&#39;s/\/articles\//\/zet\/articles\//g&#39;</span> <span class="k">$(</span>fd .md<span class="k">)</span>
</span></span></code></pre></div><p>The result:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">diff --git a/content/zet/move-to-zet.md b/content/zet/move-to-zet.md
</span></span><span class="line"><span class="cl">index 1e37283..3b817e3 <span class="m">100644</span>
</span></span><span class="line"><span class="cl">--- a/content/zet/move-to-zet.md
</span></span><span class="line"><span class="cl">+++ b/content/zet/move-to-zet.md
</span></span><span class="line"><span class="cl">@@ -6,7 +6,7 @@ tags:
</span></span><span class="line"><span class="cl"> - Zettelkasten
</span></span><span class="line"><span class="cl"> ---
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">-I<span class="s1">&#39;ve transitioned my note taking system towards a Zettelkasten system. I still use directories for folders and make copious links, but more
</span></span></span><span class="line"><span class="cl"><span class="s1">often than not I put them in the larger generic 00-zettelkasten directory in my [Obsidian](/articles/obsidian-introduction/) vault.
</span></span></span><span class="line"><span class="cl"><span class="s1">+I&#39;</span>ve transitioned my note taking system towards a Zettelkasten system. I still use directories <span class="k">for</span> folders and make copious links, but more
</span></span><span class="line"><span class="cl">often than not I put them in the larger generic 00-zettelkasten directory in my <span class="o">[</span>Obsidian<span class="o">](</span>/zet/articles/obsidian-introduction/<span class="o">)</span> vault.
</span></span></code></pre></div><p>These sites are super useful to help you formulate your expressions:</p>
<p><a href="https://sed.js.org/">https://sed.js.org/</a></p>
<p><a href="https://regex101.com/">https://regex101.com/</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Application Insights: Telemetry Sampling</title>
      <link>https://mischavandenburg.com/zet/application-insights-sampling/</link>
      <pubDate>Tue, 03 Jan 2023 08:41:09 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/application-insights-sampling/</guid>
      <description>Telemetry is the collection of measurements or other data at remote points, and transmitting that data to a receiver for monitoring.
Sampling is used to reduce telemetry traffic and costs for storage and data in Application Insights.
For small and medium sized applications sampling is generally not necessary.
Advantages of sampling:
Throttling data when the application suddenly sends a high volume of telemetry in a short time This saves costs! Keeping a pricing tier quota Reduce network traffic from telemetry collection Three different kinds of sampling:</description>
      <content:encoded><![CDATA[<p>Telemetry is the collection of measurements or other data at remote points, and transmitting that data to a receiver for monitoring.</p>
<p>Sampling is used to reduce telemetry traffic and costs for storage and data in Application Insights.</p>
<p>For small and medium sized applications sampling is generally not necessary.</p>
<p>Advantages of sampling:</p>
<ul>
<li>Throttling data when the application suddenly sends a high volume of telemetry in a short time
<ul>
<li>This saves costs!</li>
</ul>
</li>
<li>Keeping a pricing tier quota</li>
<li>Reduce network traffic from telemetry collection</li>
</ul>
<p>Three different kinds of sampling:</p>
<ul>
<li>adaptive sampling
<ul>
<li>automatically adjusts volume of telemetry</li>
<li>from ASP.NET or Azure Functions</li>
<li>only for these two</li>
</ul>
</li>
<li>fixed-rate sampling
<ul>
<li>rate is set by the administrator</li>
<li>use when you have a clear idea of the appropriate sampling percentage</li>
<li>reduces volume from
<ul>
<li>ASP.NET or ASP.NET Core server</li>
<li>Java server</li>
<li>Python applications</li>
<li>User browsers</li>
</ul>
</li>
</ul>
</li>
<li>ingestion sampling
<ul>
<li>used when monthly quota is often met</li>
<li>reduces amount of processed and retained traffic by Application Insights
<ul>
<li>less processing = less cost</li>
<li>doesn&rsquo;t reduce telemetry traffic sent from the app</li>
<li>happens at Applications Insight service endpoint</li>
</ul>
</li>
<li>disabled if SDK samples telemetry</li>
<li>can set sampling rate without redeploying the app</li>
<li>only applies when no other sampling is in effect
<ul>
<li>supports all Application Insights SDK&rsquo;s</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Pipelines: Continuous Monitoring</title>
      <link>https://mischavandenburg.com/zet/pipelines-continuous-monitoring/</link>
      <pubDate>Tue, 03 Jan 2023 08:30:03 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/pipelines-continuous-monitoring/</guid>
      <description>This term can be confusing. Initially I thought it meant monitoring of the pipelines themselves. However, in the context of Azure Release Pipelines, continuous monitoring refers to something else.
Continuous monitoring leverages metrics from other services such as Application Insights. You can set up release gates based on these metrics. For example, you can set up a release gate to roll back the deployment if an alert is being fired for high CPU usage in the application.</description>
      <content:encoded><![CDATA[<p>This term can be confusing. Initially I thought it meant monitoring of the pipelines themselves. However, in the context of Azure Release Pipelines, continuous monitoring refers to something else.</p>
<p>Continuous monitoring leverages metrics from other services such as Application Insights. You can set up release gates based on these metrics. For example, you can set up a release gate to roll back the deployment if an alert is being fired for high CPU usage in the application.</p>
<p>You can set up several of these checks. If all these checks pass, the pipeline can proceed.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Distributed Tracing</title>
      <link>https://mischavandenburg.com/zet/distributed-tracing/</link>
      <pubDate>Tue, 03 Jan 2023 07:58:44 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/distributed-tracing/</guid>
      <description>Debugging is done using call stacks in monolithic applications. Nowadays it is more common to deploy an application using a microservices architecture. Microservices make it easier to update certain parts of the application, and allow for more frequent deployments.
Using microservices does have a disadvantage: you cannot use the local call stack for debugging, because calls are sent to different microservices.
Distributed tracing is an implementation of the call stack in the cloud.</description>
      <content:encoded><![CDATA[<p>Debugging is done using <a href="/zet/call-stacks/">call stacks</a> in monolithic applications. Nowadays it is more common to deploy an application using a microservices architecture. Microservices make it easier to update certain parts of the application, and allow for more frequent deployments.</p>
<p>Using microservices does have a disadvantage: you cannot use the local call stack for debugging, because calls are sent to different microservices.</p>
<p>Distributed tracing is an implementation of the call stack in the cloud. It is usually implemented by adding an agent, <a href="/zet/sdk/">SDK</a>, or library to the service. In Azure you can enable distributed tracing via Application Insights through auto-instrumentation or SDKs.</p>
<p><a href="https://learn.microsoft.com/en-us/azure/azure-monitor/app/transaction-diagnostics">Unified cross-component transaction diagnostics</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>What is a SDK?</title>
      <link>https://mischavandenburg.com/zet/sdk/</link>
      <pubDate>Tue, 03 Jan 2023 07:50:55 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/sdk/</guid>
      <description>A software development kit (SDK) is a set of tools provided by the manufacturer of (usually) a hardware platform, operating system (OS), or programming language.
SDKs contain all the tools you need to get started. They typically contain a compiler, a debugger and an API. But they can also contain documentation and testing tools.</description>
      <content:encoded><![CDATA[<p>A software development kit (SDK) is a set of tools provided by the manufacturer of (usually) a hardware platform, operating system (OS), or programming language.</p>
<p>SDKs contain all the tools you need to get started. They typically contain a compiler, a debugger and an API. But they can also contain documentation and testing tools.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Call Stacks</title>
      <link>https://mischavandenburg.com/zet/call-stacks/</link>
      <pubDate>Mon, 02 Jan 2023 21:11:26 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/call-stacks/</guid>
      <description>When you call a function, the system sets aside space in memory for the function to do its work. Those chunks are called &amp;ldquo;stack frames&amp;rdquo; or &amp;ldquo;function frames.&amp;rdquo;
These frames are arranged in a stack. The frame for the most recently called function is always at the top of the stack. When a new function is called, it becomes the active frame, and it is on top of the stack.</description>
      <content:encoded><![CDATA[<p>When you call a function, the system sets aside space in memory  for the function to do its work. Those chunks are called &ldquo;stack frames&rdquo; or &ldquo;function frames.&rdquo;</p>
<p>These frames are arranged in a stack. The frame for the most recently called function is always at the top of the stack. When a new function is called, it becomes the active frame, and it is on top of the stack.</p>
<p>The function that is actually doing something at the moment is on top of the stack and is known as the &ldquo;active frame.&rdquo;</p>
<p>When the function finishes its work, the frame is popped off of the stack. The frame in second place becomes the active frame. It had been paused in the meantime, and now it is active again, because it is on top.</p>
<p>Functions that are not on top, are not running.</p>
<p><a href="https://www.youtube.com/watch?v=aCPkszeKRa4">This video explains it well.</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Starting a Project</title>
      <link>https://mischavandenburg.com/zet/starting-a-project/</link>
      <pubDate>Mon, 02 Jan 2023 21:00:11 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/starting-a-project/</guid>
      <description>I&amp;rsquo;m starting a project with a friend. Developing an application. We make a good team, he&amp;rsquo;s great at coding and knows the backend too.
He&amp;rsquo;ll do the development, I&amp;rsquo;m in charge of hosting. We&amp;rsquo;re setting everything up in Azure DevOps, so it is a great way to practice my Azure skills and apply the things I&amp;rsquo;ve learned in my recently obtained AZ-104 Azure Administrator certification.
Even though it is a small scale hobby project, I still plan to approach it as if it was an enterprise production application.</description>
      <content:encoded><![CDATA[<p>I&rsquo;m starting a project with a friend. Developing an application. We make a good team, he&rsquo;s great at coding and knows the backend too.</p>
<p>He&rsquo;ll do the development, I&rsquo;m in charge of hosting. We&rsquo;re setting everything up in Azure DevOps, so it is a great way to practice my Azure skills and apply the things I&rsquo;ve learned in my recently obtained <a href="/zet/articles/az-104-study-guide/">AZ-104</a> Azure Administrator certification.</p>
<p>Even though it is a small scale hobby project, I still plan to approach it as if it was an enterprise production application. I&rsquo;ll set up a full CI/CD pipeline with testing in a secure manner. Credentials stored in an Azure key vault and images pushed to a private registry.</p>
<p>This is going to be fun!</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Going to Publish Smaller, and More Often</title>
      <link>https://mischavandenburg.com/zet/move-to-zet/</link>
      <pubDate>Mon, 02 Jan 2023 20:52:50 +0100</pubDate>
      
      <guid>https://mischavandenburg.com/zet/move-to-zet/</guid>
      <description>I&amp;rsquo;ve transitioned my note taking system towards a Zettelkasten system. I still use directories for folders and make copious links, but more often than not I put them in the larger generic 00-zettelkasten directory in my Obsidian vault.
The concept of &amp;ldquo;atomic notes&amp;rdquo; is also very important in Zettelkasten methods. Notes should be small and concise.
Up until this point I&amp;rsquo;ve been publishing full articles on my blog. I came across Rob Muhlestein yesterday and I was very inspired by his setup and public zettelkasten.</description>
      <content:encoded><![CDATA[<p>I&rsquo;ve transitioned my note taking system towards a Zettelkasten system. I still use directories for folders and make copious links, but more often than not I put them in the larger generic 00-zettelkasten directory in my <a href="/zet/articles/obsidian-introduction/">Obsidian</a> vault.</p>
<p>The concept of &ldquo;atomic notes&rdquo; is also very important in Zettelkasten methods. Notes should be small and concise.</p>
<p>Up until this point I&rsquo;ve been publishing full articles on my blog. I came across <a href="https://github.com/rwxrob">Rob Muhlestein</a> yesterday and I was very inspired by his setup and public zettelkasten. I think I&rsquo;ll move to a similar approach. Still planning to write and publish full articles as well, but also including atomic notes and personal status updates.</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
